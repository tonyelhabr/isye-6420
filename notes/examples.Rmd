---
title: 'Bayesian Theory and Examples'
author: ''
output:
  rmdformats::html_docco:
    highlight: kate
    toc: true
    toc_depth: 5
---

```{r setup, include=F, cache=F}
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(
  # rows.print = 25,
  # rows.print = 25,
  echo = TRUE,
  # cache = FALSE,
  cache = TRUE,
  include = TRUE,
  fig.show = "asis",
  fig.align = "center",
  fig.width = 8,
  # size = "small",
  fig.height = 5,
  # fig.width = 5,
  # out.width = 5,
  # fig.asp = 0.75,
  warning = FALSE,
  message = FALSE
)
```

```{r postprocess, include=F, echo=F, cache=F}
.path_sans_ext <- file.path('notes', 'examples')
.path_rmd <- paste0(.path_sans_ext, '.Rmd')
# spelling::spell_check_files(.path_rmd)
```

<style type="text/css">
body, td {
  font-size: 16px;
}
code.r {
  font-size: 12px;
}
pre {
  font-size: 12px;
}
ref {
  font-style: italic;
}
hide {
  display: none;
}
.table {
  width: auto
}
</style>

## Theory

<i>
A note about notation: In general, we use capital letters to note a random variable (RV)
that has not yet taken on a value, and a lower-case letter to indicate an
"instatiation" or "manifestation" of the RV.
</i>


### Probability Distribution

These aren't all of the distributions, but these are brought up
in the examples that follow.

#### Binomial

$$
\begin{array}{c}
X \sim \mathcal{Bin}(n, p) \\
f(x)=\left(\begin{array}{l}{n} \\ 
{k}\end{array}\right) p^{X} q^{n-X}, k=0,1, \ldots, n \\
\operatorname{E}[X]=n p, \\
\operatorname{Var}(X)=n p q.
\end{array}
$$

This is used to model the number of successes $x$ in $n$ trials, 
where the probability of success is $p$. (It's a generalization of the Bernoulli distribution, which is limited to just 1 trial.)

#### Uniform

$$
\begin{array}{c}
X \sim \mathcal{U}(a, b) \\
f(x)=\frac{1}{b-a}, a \leq x \leq b, \\
\operatorname{E}[X]=\frac{a+b}{2}, \\
\operatorname{Var}(X)=\frac{(b-a)^{2}}{12}.
\end{array}
$$

Ths is commonly used if we only really know the upper and lower bounds of a distribution, and not much else.

#### Normal

$$
\begin{array}{c}
X \sim \mathcal{N}(\mu, \sigma^2) \\
f(x)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left[\frac{-(x-\mu)^{2}}{2 \sigma^{2}}\right] \\
\operatorname{E}[X]=\mu, \\
\operatorname{Var}(X)=\sigma^{2}.
\end{array}
$$

This is the "mother" of all distributions.
The sum of the values coming from any distribution will eventually 
(approximately) follow the normal distribution.
(See the Central Limit Theorem.)

#### Gamma

$$
\begin{array}{c}
X \sim \mathcal{Ga}(\alpha, \beta) \\
f(x)=\frac{\beta^{\alpha} x^{\alpha-1} e^{-\beta x}}{\Gamma(\alpha)}, x \geq 0 \\
\operatorname{E}[X]=\frac{\alpha}{\beta}, \\
\operatorname{Var}(X)=\frac{\alpha}{\beta^{2}}.
\end{array}
$$

Note that $\Gamma(\alpha) = \int_{0}^{\infty} t^{\alpha-1} e^{-t} dt.$

The Gamma distribution is a generalization of two other well-known distributions---the exponential and chi-squared distributions (which themeselves
draw upon attributes of other distributions). It shows up in a couple of conjugate pairs (to be discussed).

#### Beta

$$
\begin{array}{c}
X \sim \mathcal{Be}(\alpha, \beta) \\
f(x)=\frac{1}{\operatorname{B}(\alpha,\beta)} x^{\alpha - 1} (1-x)^{\beta-1}, 0 \leq x \leq 1, \alpha, \beta > 0. \\
\operatorname{E}[X]= \frac{\alpha}{\alpha + \beta}, \\
\operatorname{Var}(X)=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}
\end{array}
$$

Note that $\operatorname{B}(\alpha,\beta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}$

The Beta distribution is a generalization of the Gamma distribution.
It is probably the best distribution for modeling other distributions.

### Bayes' Theorem

<ref>
"Bayesian probability is an interpretation of the concept of probability, in which ... probability is interpreted ... as quantification of a personal belief." [^1]
</ref>

$$
\begin{array}{ccc}
\text{ Posterior Probability } & = & \frac{(\text{ Likelihood })(\text{ Prior Probability })}{\text{ Marginal Likelihood } } \\
P(H|E) & = & \frac{P(E|H) P(H)}{P(E)}
\end{array}
$$

<i>
Note the notation: We use $H$ to indicate "hypothesis" and $E$ to indicate evidence. Sometimes evidence is also referred to as "data" ($D$) in the literature.
</i>

Also, note that the Bayes' formula is really just a different way of stating the
conditional probability of events. (i.e. The probability of $A$ given $B$ is $P(A|B) = \frac{P(B|A) P(B)}{P(A)}$.)

Regarding the components of Bayes' formula: 

+ The prior $P(H)$ is the probability of $H$ before observing the data. Referring back to the definition of Bayes probability, it is the "personal" component. It is "elicited" by the person observing the data/performing the experiment, and its reliability is dependent on the knowledge of this person.

+ The likelihood $P(E|H)$ is the evidence about $H$ provided by the data.

+ The marginal $P(E)$ (i.e. the "normalizing constant") is the probability of the observing the data, accounting for all possibile hypotheses. It is usually what causes difficulty in calculations. We can avoid
difficulty in calculations if our problem can be modeled with conjugate pairs
(to be discussed). Also, note that the marginal may also be referred to as the
 predictive prior. A more in-depth discussion of this discussion would clarify
 why this is.

+ The posterior $P(H|E)$ is the probability that $H$ is true after the data is considered.

### Bayesian vs. Frequentist/Classical [^2]

<ref>
"Disagreements are in the nature of (1) model parameters and (2) use of conditioning:<br/>
<ul>
<li>Frequentists: (1) Parameters are <b>fixed numbers</b>. (2) Inference involves <b>optimization.</b></li>
<li>Bayesians: Parameters are <b>random variables</b>. (2) Inference involves <b>integration</b>."</li>
</ul>

</ref>

(Seethe Beta-Binomial example below.)

### Conjugacy

<ref>
"Conjugacy occurs when the posterior distribution is in the same family of probability density functions as the prior belief, but with new parameter values, which have been updated to reflect what we have learned from the data." [^3]
</ref>

#### Beta-Binomial

<ref>
Suppose we perform an experiment and estimate that the data comes from a binomial distribution $\mathcal{Bin}(n, p)$ with <b>known</b> $n$ (number of trials) and <b>unknown</b> $p$ (probability). (This is the likelihood.)
Let's say that we have a prior belief that $p$ can be modeled with the Beta distribution $\mathcal{Be}(\alpha, \beta)$ (with $\alpha, \beta$ that we choose, presumably with our "expertise"). (This is the prior.)
In the experiment we observed $x$ successes in $n$ trials. Then Bayes' rule implies that our new belief about the probability density of $p$---the posterior distribution, of $p | x$---is also the Beta distribution, with "updated" parameters. [^3]
</ref>

$$
\begin{array}{c}
p | x \sim \mathcal{Be}(\alpha + x, \beta + n - x).
\end{array}
$$

We can formalize this problem set-up as follows.

$$
\begin{array}{rclcl}
\text{ Likelihood } & : & x | p & \sim & \mathcal{Bin}(n, p) \\
\text{ Prior } & : & p & \sim & \mathcal{Be}(\alpha, \beta) \\
\text{ Posterior } & : & p | x & \sim & \mathcal{Be}(\alpha + x, \beta + n - x)
\end{array}
$$

<i>
Note that it is common to "simplify" notation, e.g. $P(p|x)$ is express simply as $p|x$.
</i>

The posterior mean reflects an "update" to the prior mean 
given $x$ and $n$.

$$
\begin{array}{rcl}
\operatorname{E}[X] & \rightarrow & \operatorname{E}[p|X] \\
\frac{\alpha}{\alpha + \beta} & \rightarrow & \frac{\alpha + x}{\alpha + \beta + n}.
\end{array}
$$

##### Example

We want to estimate the probability $p$ that a coin falls heads up. After $n = 10$ flips, we observe $X = 0$ heads.
we can model the likelihood as a $\mathcal{Bin}(n = 10, p)$ (where $p$ is unknown).
A "flat" prior for this kind of experiment is a $\mathcal{U}(0, 1)$ distribution, which happens to be equivalent to $\mathcal{Be}(1, 1)$.
What does the Beta-Binomial conjugate pair lead us to conclude about $p$?

Using $\alpha=1, \beta=1$ for our prior distribution, the posterior probability is  $\mathcal{Be}(1 + (0), 1 + (10) - (0)) = \mathcal{Be}(1, 11)$. Then the posterior mean (i.e. average or expectation) is $\hat{p} = \frac{(1)}{(1)+(11)} = \frac{1}{12}$ (because the expectation of the $\mathcal{Be}$ distribution is $\operatorname{E}[X] = \frac{\alpha}{\alpha+\beta}$.) Note that 

If we had taken the Frequentist approach (which does not incorporate priors), then
we would have concluded that $\hat{p} = \frac{X}{n} = \frac{0}{10} = 0$.

Note that the Bayes estimation of the posterior mean would be much closer to $p = 0.5$ if we had used a stronger prior (which is more realistic for something like
coin flips, where it is physically very difficult to create a "rigged" coin). For example, if we had used the prior $\mathcal{Be}(1000, 1000)$, then our posterior estimate of the mean
would have been $\hat{p} = \frac{(10000)}{(10000) + (11)} \approx 0.5$.

#### Normal-Normal

For the Normal-Normal conjugate pair, we assume that the data comes 
from a normal distribution with <b>known</b> variance $\sigma^2$ and <b>unknown</b> mean $\mu$, which we want to estimate. Also, we must "elicit"
value for mean $\mu_0$ and variance $\sigma_0^2$ for the prior distribution (which is
itself normal). (This is like how we choose $\alpha$ and $\beta$ for the prior for the Beta-Binomial conjugate pair.)

$$
\begin{array}{rclcl}
\text{ Likelihood } & : & x | \mu & \sim & \mathcal{N}(\mu, \sigma^2) \\
\text{ Prior } & : & \mu & \sim & \mathcal{N}(\mu_0, \sigma_0^2) \\
\text{ Posterior } & : & \mu | x & \sim & \mathcal{N}(\frac{\mu_0 \sigma^2 + n x \sigma_0^2}{\sigma^2 + n \sigma_0^2}, \frac{\sigma^2 \sigma_0^2}{\sigma^2 + n \sigma_0^2})
\end{array}
$$

If you look closely, you'll see that the posterior mean $\mu$ is actually
a wieghted average of the prior mean $\mu_0$ and the observed mean $\frac{x}{n}$.

##### Example

Joe models his IQ as $X \sim \mathcal{N}(\mu, 80)$.
The distribution of IQs of students at Joe's university is
$\mathcal{N}(110, 120)$.
Joe takes a single IQ test and scores $98$.


$$
\begin{array}{rclcl}
\text{ Likelihood } & : & x | \mu & \sim & \mathcal{N}(\mu, 80) \\
\text{ Prior } & : & \mu & \sim & \mathcal{N}(110, 120) \\
\text{ Posterior } & : & \mu | x & \sim & \mathcal{N}(\frac{(110) (80) + (1) (98) (120)}{(80) + (1) (120)}, \frac{(80) (120)}{(80 + (1) (120)}) \approx \mathcal{N}(102.8, 48)
\end{array}
$$


--------------------------------------------------------------------------------

[^1]: https://en.wikipedia.org/wiki/Bayesian_probability.

[^2]: Tony's Bayes Statistics class.

[^3]: https://statswithr.github.io/book/bayesian-inference.html#conjugacy

