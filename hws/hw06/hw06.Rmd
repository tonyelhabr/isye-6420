---
title: 'ISYE 6420: Homework 6'
author: 'aelhabr3'
output:
  html_document:
    css: ../styles_hw.css
    theme: cosmo
    highlight: haddock
    toc: false
---

```{r setup, include=F, cache=F}
knitr::opts_knit$set(root.dir = here::here())
knitr::opts_chunk$set(
  # rows.print = 25,
  # rows.print = 25,
  echo = TRUE,
  cache = TRUE,
  # cache.lazy = FALSE,
  include = TRUE,
  fig.show = 'asis',
  fig.align = 'center',
  fig.width = 8,
  # size = 'small',
  # fig.height = 5,
  # fig.width = 5,
  # out.width = 5,
  fig.asp = 0.75,
  warning = FALSE,
  message = FALSE
)
options(width = 300)
```

```{r postprocess, include=F, echo=F, cache=F}
.path_sans_ext <- file.path('hw06')
.path_rmd <- paste0(.path_sans_ext, '.Rmd')
# spelling::spell_check_files(.path_rmd)
```

```{r setup-1, include=F, echo=F, eval=T}
library(tidyverse)
format_num <- function(x, digits = 4) {
  fmt <- sprintf('%%.%df', digits)
  sprintf(fmt, x)
}
```

# 1. Cancer of Tongue.

## Instructions

<instructions>
Sickle-Santanello et al (1988) provide data on 80 males diagnosed with cancer of the tongue. Data are provided in the file tongue.csv|dat|xlsx. The variables in the dataset are as follows:</br>
<ul><li>Tumor DNA profile (1 - aneuploid tumor, 2 - diploid tumor);</li>
<li>Time to death or on-study time (in weeks); and</li>
<li>Censoring indicator (0=observed, 1=censored)</li></ul>
Fit the regression with tumor profile as covariate. What is the 95% Credible Set for the slope $\beta_1$?
</instructions>


## Response

```{r setup-2}
library(tidyverse)
```

```{r model_q1_ex, include=F, echo=F, eval=F}
model_q1_ex <- glue::glue_collapse('
  model
  {	
    for(i in 1 : N) {
      times[i] ~ dweib(v,lambda[i])I(censor[i],)
      lambda[i] <- exp(beta0 + beta1*type[i])
      S[i]  <- exp(-lambda[i]*pow(times[i],v));
      f[i]  <- lambda[i]*v*pow(times[i],v-1)*S[i]
      h[i] <- f[i]/S[i]
      index[i] <- i	#for plots
    }	
    beta0 ~ dnorm(0.0, 0.0001)
    beta1 ~ dnorm(0.0, 0.0001)
    v ~ dexp(0.001)
    
    # Median survival time 
    median0 <-  pow(log(2) * exp(-beta0), 1/v)
    median1 <-  pow(log(2) * exp(-beta0-beta1), 1/v)
  }
')

path_model_q1_ex <- 'model_q1_ex.txt'
write_lines(model_q1_ex, path_model_q1_ex)

data_list_q1_ex <-
  list(
    N = 90,
    type = c(
      1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1, 1, 1, 1, 1, 
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0
    ),
    censor = c(
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0,  0,  882,  892,  1031,  1033,  1306,  1335, 
      0,  1452,  1472,  0,  0,  0,  0, 
      0,  0,  0,  0,  0,  0,  0, 
      0,  0,  0,  0,  381,  0,  0, 
      0,  0,  0,  0,  0,  0,  0, 
      529,  0,  0,  0,  0,  0,  0, 
      0,  0,  0,  945,  0,  0,  1180, 
      0,  0,  1277,  1397,  1512,  1519
    ), 
    times = c(
      17,  42,  44,  48,  60,  72,  74, 
      95,  103,  108,  122,  144,  167,  170, 
      183,  185,  193,  195,  197,  208,  234, 
      235,  254,  307,  315,  401,  445,  464, 
      484,  528,  542,  567,  577,  580,  795, 
      855,  NA ,  NA,  NA,  NA,  NA,  NA, 
      1366,  NA,  NA,  1,  63,  105,  129, 
      182,  216 ,  250,  262,  301,  301,  342, 
      354,  356,  358,  380,  NA,  383,  383, 
      388,  394,  408,  460,  489,  499,  524, 
      NA,  535,  562,  675,  676,  748,  748, 
      778,  786,  797,  NA,  955,  968,  NA, 
      1245,  1271,  NA,  NA,  NA,  NA
    )
  )

inits_q1_ex <- function() {
  list(v = 1, beta0 = 0, beta1 = 0)
}

params_q1 <-
  c(
    paste0('beta', c('0', '1')),
    paste0('median', c('0', '1')),
    'v',
    'S',
    'f',
    'h'
  )
```

```{r res_sim_q1_ex, include=F, echo=F, eval=F}
# res_sim_q1_ex <-
#   R2OpenBUGS::bugs(
#     debug = TRUE,
#     data = data_list_q1_ex,
#     inits = inits_q1_ex,
#     model.file = path_model_q1_ex,
#     parameters.to.save = params_q1_ex,
#     DIC = FALSE,
#     n.chains = 1,
#     # n.iter = 50000,
#     n.iter = 5000,
#     n.burnin = 1000
#   )
```

```{r path_res_sim_q1, include=F, echo=F}
path_res_sim_q1 <- 'path_res_sim_q1.rds'
eval_model_q1 <- !fs::file_exists(path_res_sim_q1)
```

```{r model_q1, include=F, echo=F}
model_q1 <- glue::glue_collapse('
  model {	
    for(i in 1:n) {
      times[i] ~ dweib(v, lambda[i]) I(censor[i],)
      lambda[i] <- exp(beta0 + beta1 * type[i])
      S[i] <- exp(-lambda[i] * pow(times[i], v));
      f[i] <- lambda[i] * v * pow(times[i], v-1) * S[i]
      h[i] <- f[i] / S[i]
      index[i] <- i
    }	
    beta0 ~ dnorm(0.0, 0.0001)
    beta1 ~ dnorm(0.0, 0.0001)
    v ~ dexp(0.001)
    
    # Median survival time 
    median0 <- pow(log(2) * exp(-beta0), 1 / v)
    median1 <- pow(log(2) * exp(-beta0 - beta1), 1 / v)
  }
')

path_model_q1 <- 'model_q1.txt'
write_lines(model_q1, path_model_q1)
```

```{r data_list_q1, include=F, echo=F}
data_raw_q1 <- 
  'tongue.csv' %>% 
  read_csv(col_names = FALSE) %>% 
  set_names(c('type', 'times', 'censor'))

data_q1 <-
  data_raw_q1 %>% 
  mutate(idx = row_number()) %>% 
  group_by(type) %>% 
  mutate(idx_type = row_number(idx)) %>% 
  ungroup() %>% 
  select(idx, idx_type, everything()) %>% 
  # BUGs doesn't like integers.
  mutate_all(as.double) %>% 
  # Need to recode to be like "gastric.odc".
  mutate(dummy = times) %>% 
  mutate_at(vars(censor), ~ifelse(. == 0, ., dummy)) %>% 
  mutate_at(vars(times), ~ifelse(censor == 0, ., NA_real_)) %>% 
  select(-dummy)
data_q1

n_q1 <- data_q1 %>% nrow()
data_list_q1 <-
  c(list(n = n_q1), as.list(data_q1))
data_list_q1
```

```{r idx_first_censor_by_type_q1, include=F, echo=F}
idx_first_censor_by_type_q1 <-
  data_q1 %>% 
  filter(is.na(times)) %>% 
  group_by(type) %>% 
  filter(idx_type == first(idx_type)) %>% 
  ungroup()
idx_first_censor_by_type_q1
```

```{r data_q1-debug, echo=F, include=F, eval=F}
data_q1 %>% count(type)
# # Check that both of these have only one row per group.
# data_q1 %>%  filter(censor == 1) %>% count(is_not_na = times <= 0)
# data_q1 %>% group_by(type) %>% filter(censor > 1) %>% count(is_na = is.na(times))
```

```{r data_list_q1-datapasta, echo=F, include=F, eval=F}
# data_list_q1$type %>% datapasta::vector_paste()
# data_list_q1$times %>% datapasta::vector_paste()
# data_list_q1$censor %>% datapasta::vector_paste()
```

```{r res_sim_q1-setup, include=F, echo=F}
inits_q1 <-  function() {
  list(v = 1, beta0 = 0, beta1 = 0)
}

params_q1 <-
  c(
    paste0('beta', 0:1),
    paste0('median', 0:1),
    'v',
    'S',
    'f',
    'h'
  )
```

```{r res_sim_q1, include=F, echo=F, eval=eval_model_q1}
# res_sim_q1 <-
#   R2OpenBUGS::bugs(
#     # debug = TRUE,
#     data = data_list_q1,
#     inits = inits_q1,
#     model.file = path_model_q1,
#     parameters.to.save = params_q1,
#     DIC = FALSE,
#     n.chains = 1,
#     # n.iter = 50000,
#     n.iter = 10000,
#     n.burnin = 1000
#   )
```

```{r res_sim_q1_export, include=F, echo=F, eval=eval_model_q1}
# write_rds(res_sim_q1, path_res_sim_q1)
```

```{r res_sim_q1_import, include=F, echo=F}
# res_sim_q1 <- read_rds(path_res_sim_q1)
```

```{r res_sim_q1_summ-r2openbugs, include=F, echo=F, eval=F}
# res_sim_q1$summary
```

Below is the model code.

```
model {	
  for(i in 1:n) {
    times[i] ~ dweib(v, lambda[i]) I(censor[i],)
    lambda[i] <- exp(beta0 + beta1 * type[i])
    S[i] <- exp(-lambda[i] * pow(times[i], v));
    f[i]  <- lambda[i] * v * pow(times[i], v-1) * S[i]
    h[i] <- f[i] / S[i]
    index[i] <- i
  }	
  beta0 ~ dnorm(0.0, 0.0001)
  beta1 ~ dnorm(0.0, 0.0001)
  v ~ dexp(0.001)
  
  median0 <- pow(log(2) * exp(-beta0), 1 / v)
  median1 <- pow(log(2) * exp(-beta0 - beta1), 1 / v)
}

# data
list(
  n = 80,
  type = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2),
  times = c(1, 3, 3, 4, 10, 13, 13, 16, 16, 24, 26, 27, 28, 30, 30, 32, 41, 51, 65, 67, 70, 72, 73, 77, 91, 93, 96, 100, 104, 157, 167, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, 3, 4, 5, 5, 8, 12, 13, 18, 23, 26, 27, 30, 42, 56, 62, 69, 104, 104, 112, 129, 181, NA, NA, NA, NA, NA, NA),
  censor = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 61, 74, 79, 80, 81, 87, 87, 88, 89, 93, 97, 101, 104, 108, 109, 120, 131, 150, 231, 240, 400, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 67, 76, 104, 176, 231)
)

# inits
list(v = 1, beta0 = 0, beta1 = 0)
```

```{r res_sim_output_manual_q1, include=F, echo=F}
path_res_sim_output_manual_q1 <- 'q1-output.xlsx'
res_sim_output_manual_q1 <- 
  path_res_sim_output_manual_q1 %>% 
  readxl::read_excel()
res_sim_output_manual_q1
```
Note the following about the model code.

+ The model code is very similar to that from the "gastric.odc" example from lecture. Notably, we use a Weibull prior for `times`. (Well, really, since we define the initial value `v = 1`, it is initially equivalent to an exponential distribution.)
+ The regression here is a Poisson regression.
+ The data is modified to be in a workable format for OpenBUGs. Specifically, the `times` values corresponding to censored observations (i.e. `censor = 1`) are re-defined as `NA`, and the `censor` values for these observations are re-defined to the `times` values (and, otherwise, left as 0).

Below is a summary of the output, truncated because there are lots of monitored parameters.

```{r res_sim_summ_q1, include=F, echo=F}
var_lvls_q1 <-
  c(
    paste0('beta', 0:1),
    paste0('median', 0:1),
    'v',
    'deviance',
    sprintf('%s[%s]', 'S', 1:n_q1),
    sprintf('%s[%s]', 'f', 1:n_q1),
    sprintf('%s[%s]', 'h', 1:n_q1)
  )

res_sim_summ_q1 <-
  res_sim_output_manual_q1 %>% 
  # Re-order these.
  mutate_at(vars(var), ~factor(., levels = var_lvls_q1)) %>% 
  arrange(var) %>% 
  # Then re-coerce var back to its original data type.
  mutate_at(vars(var), as.character)
res_sim_summ_q1
```

```{r res_sim_summ_q1-show}
res_sim_summ_q1
```

```{r res_sim_summ_q1_filt, include=F, echo=F}
.n_show_trunc_q1 <- 5
.idx_start2_q1 <- 53 # Could find this programmatically, but whatever.
.idx_1_q1 <- 1:.n_show_trunc_q1
.idx_2_q1 <- .idx_start2_q1:(.idx_start2_q1 + .n_show_trunc_q1)
vars_filt_q1 <-
  c(
    # var_lvls_q1[1:6],
    sprintf('%s[%s]', 'S', .idx_1_q1),
    sprintf('%s[%s]', 'S', .idx_2_q1) # ,
    # sprintf('%s[%s]', 'f', .idx_1_q1),
    # sprintf('%s[%s]', 'h', .idx_1_q1)
  )
vars_filt_q1

res_sim_summ_filt_q1 <-
  res_sim_summ_q1 %>% 
  filter(var %in% vars_filt_q1)
res_sim_summ_filt_q1
```

```{r credible_set_q1, include=F, echo=F}
beta1_q1 <- res_sim_summ_q1 %>% filter(var == 'beta1')
beta1_q1
beta1_mean_q1 <- beta1_q1 %>% pull(mean)
beta1_mean_q1
beta1_mean_chr_q1 <- beta1_mean_q1 %>% format_num()
beta1_mean_chr_q1
credible_set_q1 <- c(beta1_q1$val2.5pc, beta1_q1$val97.5pc)
credible_set_q1
credible_set_chr_q1 <- credible_set_q1 %>% format_num()
credible_set_chr_q1
```


From the output shown above, we see that the posterior mean for `beta1` is `r beta1_mean_chr_q1`, <response>and we see that 95% CS is [`r credible_set_chr_q1[1]`, `r credible_set_chr_q1[2]`].</response>

### Aside: A Closer Evaluation

Below is a subset of the results from before. Specifically, the first `r .n_show_trunc_q1` estimates of the `S` "array" of monitored parameters corresponding to each tumor `type` group are shown.

```{r res_sim_summ_filt_q1-show-pre, include=F, echo=F}
opt_tibble_print_min <- getOption('tibble.print_min')
n_res_sim_summ_filt_q1 <- res_sim_summ_filt_q1 %>% nrow()
options(tibble.print_min = n_res_sim_summ_filt_q1)
```

```{r res_sim_summ_filt_q1-show}
res_sim_summ_filt_q1
```

```{r res_sim_summ_filt_q1-show-post, include=F, echo=F}
options(tibble.print_min = opt_tibble_print_min)
```

```{r res_sim_summ_filt_s_q1, include=F, echo=F}
res_sim_summ_filt_s_q1 <-
  res_sim_summ_q1 %>% 
  filter(var %>% str_detect('^S')) %>% 
  mutate(idx = row_number()) %>% 
  inner_join(data_q1) %>% 
  mutate_at(vars(type), as.factor) %>% 
  select(type, idx, idx_type, everything())
res_sim_summ_filt_s_q1
```

```{r viz-funcs, include=F, echo=F}
theme_custom <- function(...) {
  theme_light(base_size = 14) +
    theme(
      legend.position = 'bottom',
      # legend.title = element_blank(),
      axis.title.x = element_text(hjust = 1),
      axis.title.y = element_text(hjust = 1),
      ...
    )
}

export_png <-
  function(x,
           path,
           ...,
           units = 'in',
           width = 8,
           height = 5) {
    ggsave(
      plot = x,
      filename = path,
      units = units,
      width = width,
      height = height,
      ...
    )
  }
```

Below is a plot of the survival curves corresponding to the two types of tumors (1 for aneuploid tumor, 2 for diploid tumor). (These are the `S` parameter estimates.)

```{r path_viz_s_q1, include=F, echo=F}
path_viz_s_q1 <- 'viz_s_q1.png'
eval_viz_s_q1 <- !fs::file_exists(path_viz_s_q1)
```

```{r viz_s_q1, include=F, echo=F, fig.show=F}
viz_s_q1 <-
  res_sim_summ_filt_s_q1 %>% 
  ggplot() +
  aes(x = idx_type, y = mean, color = type) +
  geom_line(size = 1.1) +
  geom_point(
    data = 
      idx_first_censor_by_type_q1 %>% 
      mutate_at(vars(type), as.factor) %>% 
      inner_join(res_sim_summ_filt_s_q1),
    size = 3
  ) + 
  guides(color = guide_legend(title = 'Tumor Type', override.aes = list(size = 3))) +
  scale_color_manual(values = c('red', 'blue')) +
  theme_custom() +
  labs(
    subtitle = 'Survival Probability',
    caption = 'First censored data points shown as points.',
    x = 'Index of Observation',
    y = 'Posterior Mean of Survival Probability'
  )
viz_s_q1
```

```{r viz_s_q1_export, include=F, echo=F, eval=eval_viz_s_q1}
export_png(
  viz_s_q1,
  path = path_viz_s_q1,
)
```

```{r viz_s_q1-show, include=T, echo=F}
knitr::include_graphics(path_viz_s_q1)
```

We observe that there is a noticeable "jump" in the survival probability curve for the second tumor type group. This observation corresponds to the first censored value in the group. From my understanding, such a phenomenon is not necessarily impossible for an experiment where there is a relatively significant sample that is censored (here, 6 of 28 for the second group). Nonetheless, the "pseudo-discontinuity" suggests that there could be a better way of modeling the group of observations. But, since this is not asked of us, I leave this for another time.


# 2. Airfreight Breakage with Missing Data.

## Instructions

<instructions>
A substance used in...
</instructions>


## Response

```{r q2-0, include=F, echo=F}
x <- c(2, 1, 0, 2, NA_integer_, 3, 1, 0, 1, 2, 3, 0, 1, NA_integer_, NA_integer_)
y <- c(NA_integer_, 16, 9, 17, 12, 22, 13, 8, NA_integer_, 19, 17, 11, 10, 20, 2)
```

```{r path_res_sim_q2, include=F, echo=F}
path_res_sim_q2 <- 'path_res_sim_q2.rds'
eval_model_q2 <- !fs::file_exists(path_res_sim_q2)
```

```{r model_q2, include=F, echo=F}
model_q2 <- glue::glue_collapse('
  model{
    for(i in 1:n) {
      y[i] ~ dpois(lambda[i])
      log(lambda[i]) <- beta0 + beta1 * x[i]
    }
    for(i in 1:n) {
      x[i] ~ dpois(2)
    }
    beta0 ~ dnorm(0, 0.0001)
    beta1 ~ dnorm(0, 0.0001)
    lambdahat <- exp(beta0 + beta1)
    log(pred1) <- beta0 + beta1 * (4)
  }
')

path_model_q2 <- 'model_q2.txt'
write_lines(model_q1, path_model_q2)
```

```{r data_list_q2, include=F, echo=F}
data_raw_q2 <- 
  tibble(
    x = x,
    y = y
  )
data_q2 <- data_raw_q2
n_q2 <- data_q2 %>% nrow()
data_list_q2 <-
  c(list(n = n_q2), as.list(data_q2))
data_list_q2
```

```{r data_list_q2-datapasta, echo=F, include=F, eval=F}
# data_list_q2$x %>% datapasta::vector_paste()
# data_list_q2$y %>% datapasta::vector_paste()
```

```{r res_sim_q2-setup, include=F, echo=F}
inits_q2 <-  function() {
  list(beta0 = 0, beta1 = 0)
}

params_q2 <-
  c(
    'x',
    'y',
    paste0('beta', 0:1),
    'lambdahat',
    'pred1'
  )
```

```{r res_sim_q2, include=F, echo=F, eval=eval_model_q2}
# res_sim_q2 <-
#   R2OpenBUGS::bugs(
#     debug = TRUE,
#     data = data_list_q2,
#     inits = inits_q2,
#     model.file = path_model_q2,
#     parameters.to.save = params_q2,
#     DIC = FALSE,
#     n.chains = 1,
#     # n.iter = 50000,
#     n.iter = 10000,
#     n.burnin = 1000
#   )
```

```{r res_sim_output_manual_q2, include=F, echo=F}
path_res_sim_output_manual_q2 <- 'q2-v2-output.xlsx'
res_sim_output_manual_q2 <- 
  path_res_sim_output_manual_q2 %>% 
  readxl::read_excel()
res_sim_output_manual_q2
```

The model code below is written so as to answer all parts of this question. (In particular, `lambdastar` corresponds to the expected average value asked for in (b) and `pred1` corresponds to the prediction asked for in (c).)

```
model {
  for(i in 1:n) {
    y[i] ~ dpois(lambda[i])
    lambda[i] <- exp(beta0 + beta1 * x[i])
  }
  for(i in 1:n) {
    x[i] ~ dpois(2)
  }
  beta0 ~ dnorm(0, 0.0001)
  beta1 ~ dnorm(0, 0.0001)
  lambdastar <- exp(beta0 + (4) * beta1)
  pred1 ~ dpois(lambdastar)
}

# data
list(
  n = 15,
  x = c(2, 1, 0, 2, NA, 3, 1, 0, 1, 2, 3, 0, 1, NA, NA),
  y = c(NA, 16, 9, 17, 12, 22, 13, 8, NA, 19, 17, 11, 10, 20, 2)
)

# inits
list(
  beta0 = 0,
  beta1 = 0
)
```


Note that we make the assumption that the probability of a value missing does not depend on the data that is missing, i.e. we assume that the data is missing at random (MAR). Thus, we simply specify missing $X$ using a reasonable non-negative distribution, such as $\mathcal{Pois}(2)$, as suggested in the hint. (This corresponds to `x[i] ~ dpois(2)` in the model code.) If we did not assume this, then we would need to change the model code from its current form.

Below is a summary of the output from OpenBUGs.

```{r res_sim_summ_q2, include=F, echo=F}
res_sim_summ_q2 <- res_sim_output_manual_q2
res_sim_summ_q2
```

```{r res_sim_summ_q2-show, echo=F}
res_sim_summ_q2
```

```{r .pull_xy_est, include=F, echo=F}
.pull_est <- function(data, .var) {
  data %>% filter(var == .var) %>% pull(mean)
}
.pull_est_q2 <- purrr::partial(.pull_est, data = res_sim_summ_q2, ... = )
.pull_xy_est <- function(data, prefix = c('x', 'y'), idx) {
  prefix <- match.arg(prefix)
  data %>% filter(var == sprintf('%s[%s]', prefix, idx)) %>% pull(mean)
}
.pull_x_est_q2 <- purrr::partial(.pull_xy_est, data = res_sim_summ_q2, prefix = 'x', ... = )
.pull_y_est_q2 <- purrr::partial(.pull_xy_est, data = res_sim_summ_q2, prefix = 'y', ... = )
```

### a

```{r deviance_q2, include=F, echo=F}
deviance_q2 <- .pull_est_q2('deviance')
deviance_q2
```

As shown in the output above, <response>the deviance of the fit is `r deviance_q2`.</response>


### b

The posterior estimate and 95% CS for $X = 4$ correspond to `lambdastar` from the output shown above.

```{r credible_set_q2b, include=F, echo=F}
pred1_q2b <- res_sim_summ_q2 %>% filter(var == 'lambdastar')
pred1_q2b
pred1_mean_q2b <- pred1_q2b %>% pull(mean)
pred1_mean_q2b
credible_set_q2b <- c(pred1_q2b$val2.5pc, pred1_q2b$val97.5pc)
credible_set_q2b
```

From the output shown above, we see that the posterior mean (for `lambdastar`) is `r pred1_mean_q2b`, <response>and we see that the 95% CS is [`r credible_set_q2b[1]`, `r credible_set_q2b[2]`].</response>

### c

```{r credible_set_pred1_q2c, include=F, echo=F}
pred1_q2c <- res_sim_summ_q2 %>% filter(var == 'pred1')
credible_set_pred1_q2c <- c(pred1_q2c$val2.5pc, pred1_q2c$val97.5pc)
credible_set_pred1_q2c
pred1_q2c <- .pull_est_q2('pred1')
pred1_q2c
```

<response>
The prediction for $X = 4$ is indicated by `pred1` in the output shown above (a). It has a posterior mean of `r pred1_q2c `. Also, note that this prediction has a CS of [`r credible_set_pred1_q2c[1]`, `r credible_set_pred1_q2c[2]`], which is larger than that found in (b). (The standard deviation `sd` of the prediction here (for `pred1` is also larger than that in (b) (for `lambdastar`).) This is because the CS here accounts for uncertainty about the prediction, as well as the uncertainty about $\sigma$; on the other hand, the CS in (b) only accounts for uncertainty about the prediction `pred1`.
</response>

Drawing upon frequentist statistics, one might say that the interval here is analogous to a prediction interval, whereas the interval in (b) is analogous to a confidence interval. Prediction intervals are always equal to or greater than confidence intervals because they account for additional uncertainty.

<hide>
See p. 187 at https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/bugsbook_chapter9.pdf for more about this explanation.
</hide>

### d

```{r xy_ests_q2, include=F, echo=F}
x_5_q2 <- .pull_x_est_q2(5)
x_14_q2 <- .pull_x_est_q2(14)
x_15_q2 <- .pull_x_est_q2(15)
y_1_q2 <- .pull_y_est_q2(1)
y_9_q2 <- .pull_y_est_q2(9)
```

As shown in the output above (a), <response>the estimates (of the posterior means) are as follows.</response>

+ $X_{5}$ = `r x_5_q2`

+ $X_{14}$ = `r x_14_q2`

+ $X_{15}$ = `r x_15_q2`

+ $Y_{1}$ = `r y_1_q2`

+ $Y_{9}$ = `r y_9_q2`.

